{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name:   Anik Manik\n",
    "\n",
    "# Email address:   iamanik4@gmail.com\n",
    "\n",
    "# Contact number:   9477672426\n",
    "\n",
    "# Anydesk address:   400 728 410\n",
    "\n",
    "# Years of Work Experience: 2.6 years\n",
    "\n",
    "# Date:   24th Jan 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Case Study 2: SIIM-ACR Pneumothorax Segmentation\n",
    "### Identify Pneumothorax disease in chest x-rays\n",
    "https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src='https://i.imgur.com/Iv65NAG.jpg'>\n",
    "Image Source: https://www.svhlunghealth.com.au/Images/UserUploadedImages/3457/Pneumothorax%20still.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Pneumothorax disease?\n",
    "\n",
    "A pneumothorax is when the lung has collapsed due to air entering the space around your lungs (known as the pleural space). In a healthy body, the lungs are touching the walls of the chest. Air can enter the pleural space through an opening in your chest wall or in the lung. Air in the pleural space creates an increase in pressure around the lung and causes it to collapse. The lung may fully collapse, but most often only a part of it collapses. This collapse can also put pressure on the heart, causing further symptoms.\n",
    "\n",
    "A pneumothorax can be severe, depending on how much air is trapped in the pleural space. A small amount of trapped air can usually resolve by itself, provided there are no other complications. Larger amounts of trapped air can be serious and lead to death if medical treatment is not obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causes:\n",
    "\n",
    "### 1. Primary spontaneous: \n",
    "Primary spontaneous pneumothorax(PSP) occurs in young people (aged 15-34) without any history of lung disease. The direct cause of PSP is unknown. People at risk include smokers, tall men and those who have had a family member with a pneumothorax.\n",
    "\n",
    "### 2. Secondary spontaneous:\n",
    "Secondary spontaneous pneumothorax (SSP) can be caused by a variety of lung diseases(such as chronic obstructive pulmonary disease, cystic fibrosis, tuberculosis,  pneumonia, lung cancer, sarcoidosis, pulmonary fibrosis or cystic lung diseases) and tissue disorders(such as Marfan’s Syndrome). SSP carries more serious symptoms than PSP, and it is more likely to cause death.\n",
    "\n",
    "### 3. Traumatic pneumothorax:\n",
    "A traumatic pneumothorax is the result of an impact or injury. Potential causes include blunt trauma or an injury that damages the chest wall and pleural space.\n",
    "One of the most common ways this occurs is when someone fractures a rib. The sharp points of the broken bone can puncture the chest wall and damage lung tissue. Other causes include sports injuries, car accidents, and puncture or stab wounds.\n",
    "\n",
    "### 4. Tension pneumothorax\n",
    "Tension pneumothorax is caused by a leak in the pleural space that resembles a one-way valve. As a person inhales, the air leaks into the pleural space and becomes trapped. It cannot be released during an exhale. This process leads to increased air pressure in the pleural space that is life-threatening and needs immediate treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symptoms:\n",
    "1. Shortness of breath\n",
    "2. Abnormally fast heart rate (known as tachycardia)\n",
    "3. Chest pain, which may be more severe on one side of the chest\n",
    "4. Sharp pain when inhaling\n",
    "5. Blue discoloration of the skin or lips\n",
    "6. Cold sweats <br>\n",
    "\n",
    "Some cases of pneumothorax have almost no symptoms. These can only be diagnosed with an X-ray or another type of scan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosis:\n",
    "Diagnosis of a pneumothorax is typically done via a <b>chest X-ray</b>, which takes images to detect the presence of air in the pleural space (area round the lungs). A CT scan and thoracic ultrasound can also be used to help diagnose a pneumothorax.\n",
    "\n",
    "A doctor (radiologist) then examines the X-ray report to diagnose pneumothorax and the affected area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem:\n",
    "Pneumothorax is typically detected on chest X-ray, examined by a doctor or a radiologist. But this requires manual effort. Since current imaging volumes are large in number, it takes a long time to review every image and prepare report. Pneumothorax can cause life threatening emergency due to lung collapse and respiratory or circulatory distress if it is not detected early.\n",
    "\n",
    "Our objective is to build an automated method to predict X-rays with pneumothorax and segmentize the affected area. This will help to prioritize the treatment of patients with pneumothorax. Automatic image segmentation can assist doctors in the treatment and diagnosis of diseases with higher accuracy, accelerate diagnosis process, and improve efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Formulation:\n",
    "Build an automatic image segmentation model using deep convolution network to predict pneumothorax and segmentize the affected area. We will use the given images and RLE masks to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Constraints:\n",
    "\n",
    "1. There is no such latency constraints for this problem but the model should predict within few minutes.\n",
    "2. Along with prediction the model should segmentize the pneumothorax affected area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset column analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6904.151787520...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.13666.15178752...</td>\n",
       "      <td>557374 2 1015 8 1009 14 1002 20 997 26 990 32 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.11028.15178752...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.10366.15178752...</td>\n",
       "      <td>514175 10 1008 29 994 30 993 32 991 33 990 34 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.10016.15178752...</td>\n",
       "      <td>592184 33 976 58 956 73 941 88 926 102 917 109...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId  \\\n",
       "0  1.2.276.0.7230010.3.1.4.8323329.6904.151787520...   \n",
       "1  1.2.276.0.7230010.3.1.4.8323329.13666.15178752...   \n",
       "2  1.2.276.0.7230010.3.1.4.8323329.11028.15178752...   \n",
       "3  1.2.276.0.7230010.3.1.4.8323329.10366.15178752...   \n",
       "4  1.2.276.0.7230010.3.1.4.8323329.10016.15178752...   \n",
       "\n",
       "                                       EncodedPixels  \n",
       "0                                                 -1  \n",
       "1  557374 2 1015 8 1009 14 1002 20 997 26 990 32 ...  \n",
       "2                                                 -1  \n",
       "3  514175 10 1008 29 994 30 993 32 991 33 990 34 ...  \n",
       "4  592184 33 976 58 956 73 941 88 926 102 917 109...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_rle = pd.read_csv(\"train-rle.csv\")\n",
    "train_rle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given data consists of ImageId and EncodedPixels. For every ImageId we have an image in DICOM format. EncodedPixels with '-1' value indicates the image is without pneumothorax. Images with pneumothorax have mask in run-length-encoded (RLE) format. We have to decode and create the mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metric:\n",
    "\n",
    "I have given the images along with masks. I have to train model using that data and predict masks for the test data. So, this is a Semantic Image Segmentation problem.\n",
    "\n",
    "In this Semantic Image Segmentation problem I am going to use 2 most commonly used  loss metric.\n",
    "\n",
    "reference: https://www.jeremyjordan.me/semantic-segmentation/#loss\n",
    "\n",
    "### 1. Pixel-wise cross entropy loss:\n",
    "This loss examines each pixel individually, comparing the class predictions (depth-wise pixel vector) to our one-hot encoded target vector.<br>\n",
    "Pixel wise loss is calculated as the log loss summed over all possible classes.\n",
    "<img src='https://i.imgur.com/ztsL0Bf.jpg'>\n",
    "\n",
    "\n",
    "### 2. Dice loss:\n",
    "<h4>Dice Loss = 1 - Dice Coefficient</h4>\n",
    "\n",
    "<h4>Where Dice Coefficient(D) = </h4> <img src='https://i.imgur.com/bQLEpyT.jpg' style=\"width:300px;height:200px;\">\n",
    "Here, pi = predicted pixel values. <br>\n",
    "gi = groung truth pixel values. <br>\n",
    "In image segmentation scenatio the values of pi and gi are either 0 or 1. <br>\n",
    "1 --> pixel is a boundary <br>\n",
    "0 --> pixel is not a boundary <br>\n",
    "In the dice coefficient, <br>\n",
    "Numerator --> 2 * Sum of correctly predicted boundary pixels. (when pi and gi both are 1) <br>\n",
    "Deniminator --> Sum of total boundary pixels of both predicted and ground truth.\n",
    "\n",
    "<img src='https://i.imgur.com/arO1iaY.jpg'>\n",
    "\n",
    "### 3. Intersection over Union (IoU) Score:\n",
    "\n",
    "reference:https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
    "\n",
    "The Intersection over Union (IoU) metric, also referred to as the Jaccard index. This is a method to quantify the percent overlap between the target mask and our prediction output. This metric is closely related to the Dice coefficient.\n",
    "\n",
    "The IoU metric measures the number of pixels common between the target and prediction masks divided by the total number of pixels present across both masks.\n",
    "\n",
    "<img src='https://i.imgur.com/ZtLfjDF.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research-Papers/Solutions/Architectures/Kernels\n",
    "\n",
    "Mention the urls of existing research-papers/solutions/kernels on your problem statement and in your own words write a detailed summary for each one of them. If needed you can include images or explain with your own diagrams. it is mandatory to write a brief description about that paper. Without understanding of the resource please don’t mention it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Blog: An overview of semantic image segmentation.\n",
    "https://www.jeremyjordan.me/semantic-segmentation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog it is discussed that how convolution neural network is used for semantic image segmentation. Image segmentation is a computer vision task in which we label specific regions of an image according to what's being shown.\n",
    "<img src='https://i.imgur.com/lBACcWk.jpg'>\n",
    "\n",
    "The goal of semantic image segmentation is to label each pixel of an image with a corresponding class of what is being represented. Here we are not separating instances of the same class. If we have 2 objects of the same category in the input image, we are not separating them. In the above image we are separating Person, Bicycle and Background. But we are not separating individual person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/harhgyu.jpg'>\n",
    "\n",
    "Our objective is to take an input image (RGB- height×width×3 /Grayscale - height×width×1) and output a segmentation map where each pixel contains a class label represented as an integer (height×width×1).\n",
    "\n",
    "For this task we will create our target by one-hot encoding the class labels i.e creating an output channel for each of the possible classes. So, the number of output channel will be equal to number to target labels. Then a prediction can be collapsed into a segmentation map by taking the argmax of each depth-wise pixel vector to get a output shape = height×width×1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing an architecture:\n",
    "### Approach 1:\n",
    "### Stack a number of convolutional layers:\n",
    "This is a naive approach towards constructing a neural network for this semantic segmentation task. In this approach we need to  simply stack a number of convolutional layers (with same padding to preserve dimensions) and output a final segmentation map.\n",
    "<img src='https://i.imgur.com/LJo3lnO.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2:\n",
    "### Encoder/Decoder structure:\n",
    "Here we downsample the spatial resolution of the input, developing lower-resolution feature mappings which are learned to be highly efficient at discriminating between classes, and the upsample the feature representations into a full-resolution segmentation map.\n",
    "<img src='https://i.imgur.com/3OioTse.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3:\n",
    "### Use AlexNet as encodder appending a decoder module with transpose convolutional layers:\n",
    "The author used existing image classification AlexNet network to serve as encoder module of this network, appending a decoder module with transpose convolutional layers to upsample the coarse feature maps into a full-resolution segmentation map.\n",
    "<img src='https://i.imgur.com/Frlpj7C.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach4:\n",
    "### U-Net architecture:\n",
    "In the previous AlexNet based model, the encoder module reduces the resolution of the input by a factor of 32, the decoder module struggles to produce fine-grained segmentations. This is because semantic segmentation faces an inherent tension between semantics and location. <br>\n",
    "To address this problem the author added skip connections from earlier layers and summing feature maps. These skip connections from earlier layers in the network (prior to a downsampling operation) should provide the necessary detail in order to reconstruct accurate shapes for segmentation boundaries.\n",
    "<img src='https://i.imgur.com/ELfWFQt.jpg'>\n",
    "\n",
    "More concretely the concept is proposed in U-Net architecture which consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. This U-Net architecture is very popular for image segmentation. There are some advanced varients of U-Net which performs better than U-Net for image segmentation task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Research Paper\n",
    "### U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "https://www.semanticscholar.org/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/L3WeIfs.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left part of this U-Net architecture is contracting path which consists of encoders. This path is also known as downsampling path. The right part is called expansive path and consists of decoders, also known as upsampling path.\n",
    "\n",
    "Skip conncetions are there in between from encoder to decoder, this connections helps to get localizations of the objects in semantic segmentation task.\n",
    "\n",
    "The contracting path follows the typical architecture of a convolutional block. Each convolution block consists of 2 convolution layer followed by a maxpool layer. In the last convolution block of encoder part there is no maxpool layer. This downsampling part increase the number of layers of the image and decrease the resolution of the image. We are capturing the context information using this encoder part.\n",
    "\n",
    "In expansive path also we have convolution blocks. Each convolution block consists of 2 convolution layer followed by a transpose convolution or upsampling layer. This part increase the size of the image and decrease the number of layers. For every decoder block concatination is done from encoder to decoder to get the localization information. Encoder part helps to find out the type of the object and decoder part helps to get the localization information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Research Paper\n",
    "### DC-UNet: Rethinking the U-Net Architecture with Dual Channel Efficient CNN for Medical Images Segmentation\n",
    "https://www.semanticscholar.org/paper/DC-UNet%3A-Rethinking-the-U-Net-Architecture-with-CNN-Lou-Guan/5fb044a4a3925f1d95260af9d5b95e47c1ee7e3c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/K1C1CR5.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though U-Net performs well in medical image segmentation task, there is some limitations of it. DC-UNet comes up with some modifications of classical U-Net model.\n",
    "1. Designed efficient CNN architecture to replace encoder and decoder.\n",
    "2. Applied residual module to replace skip connection between encoder and decoder to improve based on the-state-of-the-art U-Net model.\n",
    "3. Used the Tanimoto similarity to replace the Jaccard similarity for gray-to-gray image comparisons.\n",
    "\n",
    "With these modifications DC-UNet is a potential successor to the U-Net architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Existing Solution:\n",
    "### 2nd Place Solution:\n",
    "\n",
    "This solution consists of 2 parts. Classification and Segmentation.\n",
    "#### Classification: \n",
    "In this part Unet is used to classify whether an image is pneumothorax or not.<br>\n",
    "Loss = BCE + focal loss<br>\n",
    "Augmentation: hflip, scale, rotate, bright, blur<br>\n",
    "Backbone: seresnext 50, seresnext101, efficientnet-b3\n",
    "\n",
    "#### Segmentation:\n",
    "Two models are used to segment, unet and deeplabv3.<br>\n",
    "Imaged which consists of pneumothorax is used.<br>\n",
    "Loss = Dice Loss<br>\n",
    "Augmentation: hflip, scale, rotate, bright, blur<br>\n",
    "Backbone: seresnext 50, seresnext101, efficientnet-b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Existing Solution:\n",
    "### 6th Place Solution:\n",
    "https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107743\n",
    "\n",
    "This solution is based on EncodingNet (ResNets, 512 and 1024 size) and UNet (EfficientNet4, se-resnext50, SENet154 with 512, 640 and 1024 sizes).\n",
    "\n",
    "1. Best augmentations were related to crops and rotations.\n",
    "2. contrast and brightness transformations didn't work well.\n",
    "3. Loss: BCE + Dice\n",
    "4. Lower image sizes reduced score a lot so model with full sized image resulted better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Cut Approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection:\n",
    "\n",
    "Data is provided by the organizer in kaggle platform. So, I don't need to spend time do data collection. <br>\n",
    "https://www.kaggle.com/seesee/siim-train-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning:\n",
    "X-ray images are provided in DICOM  format, which consists of image along with addithonal informations. I need to extract these informations for EDA. Then I need to convert these images in PNG format to train my model.\n",
    "\n",
    "Masks are given in run length encoded format, I need to decode it to create mask in PNG format for every image.\n",
    "\n",
    "I need to split the data into train and validation set for every image along with it's original mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentations I want to use:\n",
    "1. crop\n",
    "2. rotation\n",
    "3. hflip\n",
    "4. bright\n",
    "5. blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metric:\n",
    "Loss = Cross Entropy Loss + Dice Loss <br>\n",
    "Score = IoU Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling:\n",
    "\n",
    "First I am going to use pretrained models. For this task I will use the below combinations.\n",
    "\n",
    "Model: Unet and Linknet <br>\n",
    "Backbone: Resnet34,  Resnet50<br>\n",
    "Encoder Weight: imagenet <br>\n",
    "\n",
    "I will also define my own Unet model and and try to do some modifications to make it work better.<br>\n",
    "Then I will define some advanced Unet model like DC-UNet. I will train the model and compare the performances to pick the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction:\n",
    "After model is trained I will predict the validation mask and plot original image along with the original and predicted mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
